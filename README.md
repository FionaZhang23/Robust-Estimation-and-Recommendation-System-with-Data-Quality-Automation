# Robust-Estimation-and-Recommendation-System-with-Data-Quality-Automation

## ðŸ“Œ Overview

This project implements an end-to-end machine learning pipeline for **estimation and recommendation tasks**, following the CRISP-DM framework. It includes:

- Automated data quality checks (missing values, duplicates, value ranges, etc.)
- Data leakage detection and mitigation
- Estimation of housing prices using real-world data
- Recommendation modeling to predict fantasy book ratings
- Training at scale using HPC (High Performance Computing) via SLURM job submission

The solution was developed as part of CSC373/673: Data Mining at Wake Forest University (Spring 2025).

---

## ðŸ§  Methodology: CRISP-DM Pipeline

This project is structured into the following phases:

| Phase | Task |
|-------|------|
| **II** | Data understanding & quality checking |
| **III** | Data preparation & modeling (housing + books) |
| **IV** | Evaluation and performance improvement |
| **V** | HPC training with large-scale fantasy book reviews |

---

## ðŸ“‚ Project Structure

```bash
data/                             # Raw data files
â””â”€â”€ feature_descriptions.csv

output/                           # Reports and model results
â”œâ”€â”€ data_quality_report.csv
â”œâ”€â”€ fantasy_modeling_report.txt
â””â”€â”€ fantasy_model_report(part4).txt

scripts/                          # All Python scripts
â”œâ”€â”€ __init__.py
â”œâ”€â”€ check_quality.py              # Phase II: Data quality + leakage check
â”œâ”€â”€ transformers.py               # Phase III: Custom Transformer class
â”œâ”€â”€ utils.py                      # Phase IV: Feature engineering utils
â””â”€â”€ assignment_2.py               # Main execution script

slurm/                            # SLURM job script for HPC
â””â”€â”€ assignment_2.slurm

README.md                         # Project overview and instructions
requirements.txt                  # Python dependencies

